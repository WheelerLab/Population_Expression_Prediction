#These steps are a continuation of 'Steps_Leading_to_Imputation', and uses files generated from those steps.
# The merge steps (1 and 3) for merging 1000 genomes data with the imputation output was not needed for MKK as all samples were imputed.

1) Divide the 1000 Genomes Project data by population, keeping the samples with expression data. Filter for SNPs with a MAF > 0.01.
  'for i in {1..22}; do vcftools --gzvcf /home/wheelerlab1/Data/1000_genomes_phase3/ALL.chr${i}.phase3_shapeit2_mvncall_integrated_v5a.20130502.genotypes.vcf.gz --maf 0.01 --keep POP.list --recode --out POP_TGP_chr${i}; done'
    Output for each chromosome:
      POP_TGP_chr1.vcf
    gzip these.

2) Obtain the imputation output files using the emailed encription key, and remove SNPs with R2 < 0.8. Make sure these files are gzipped.
  'for i in {1..22}; do bcftools filter -i 'R2>0.8' chr${i}.dose.vcf.gz > POP_chr${i}.R20.8.dose.vcf; done'
  gzip these.

3) Merge the filtered imputation output with the 1000 Genomes files. Use '/home/wheelerlab1/Data/merge_vcf/merge.py'.
  'for i in {1..22}; do python merge.py POP_TGP_chr${i}.vcf.gz POP_chr${i}R20.8.dose.vcf.gz POP_merge_chr${i}.vcf.gz; done'
    Output for each chromosome:
      POP_merge_chr1.vcf.gz

4) QC on merged files using vcftools, keeping only SNPs with MAF > 0.01 and HWE P > 1e-06.
  'for i in {1..22}; do vcftools --gzvcf POP_merge_chr${i}.vcf.gz --maf 0.01 --hwe 1e-06 --recode --out POP_filtered_chr${i}; done'
    Output for each chromosome:
      POP_filtered_chr1.recode.vcf

***The QC merged files are in All_Populations/

5) Run PEER. Can either do full script to generate plots for comparison, or simply generate the residuals file, which is needed for generating the MatrixeQTL files.
  Use '05_PEER_Plots_With_Sex_Covariate.R'
  The residuals file is needed for MatrixeQTL
  Output:
    'POPResiduals.sexcov.10.txt'
  Manually go back in using nano and add 'ID ' to the start of the first line.
  ***The residual files for each pop are in All_Populations/

6) Run Matrix eQTL. Can either perform a full analysis, or solely make the files you need for elastic net.
  a)  Use '06_Matrix_eQTL_Expression_File_Conversion.R' to generate the Expression and Gene Location files.
  b)  Use '07_SNPs.py' to generate the SNPs and SNPs Location files.
  ***These four sets of files are in All_Populations/
  c)  Use '09_Matrix_eQTL_script.R' to run Matrix eQTL.

7) Run elastic net using script from Dr. Wheeler. Update it with the proper file paths.
   This is done three times, with the alpha values of 0, 0.5, and 1. 0.5 is shown as the alpha argument in the example.
   This is nice to have run in the background because it will take a day or two. 
   Also maybe do chromosome 22 first to make sure everything runs properly. You can then modify the wrapper to be '{1..21}'.
  'for i in {1..22}; do R --no-save < HapMap3_elasticNet.CV.r --args ${i} 0.5 POP > POP_chr${i}_alpha0.5.log; done'

8) Generate '.db' files for PrediXcan.
    a) Use '500_concatenate.sh', modifying the file names to concatentate the elastic net files.
        Make sure the appropriate files contain the terms '_merged_weights' and '_merged_expression'.
    b) Use '400_generate_sqlite_dbs.py' alongside the shell script '600_POP_generate_db_files.sh', modifying the file names in the shell script.
        It may appear as though there is an error. It will still output the three files ('merged_weights') you need for PrediXcan.
    ***Database files for each individual population are in the ElasticNet section of each population in All_Populations.

9) Run PrediXcan.
    
